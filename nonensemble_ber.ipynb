{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ber_metrics import BEREstimator\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adult Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ALL INPUT FEATURES INCLUDING PROTECTED VARS ---\n",
      "Mahalanobis upper bound: 0.2383977285329773\n",
      "Bhattacharrya upper bound: (0.00018925250028173357, 0.01375560554002971)\n",
      "Nearest Neighbor upper bound: (0.11550679563529465, 0.20432995159472184)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = pickle.load(open('Data/adult_income/processed_data.pkl', 'rb'))\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "adult_estimator = BEREstimator(X_train, y_train)\n",
    "print(\"--- ALL INPUT FEATURES INCLUDING PROTECTED VARS ---\")\n",
    "print(\"Mahalanobis upper bound: {}\".format(adult_estimator.mahalanobis_bound()))\n",
    "print(\"Bhattacharrya upper bound: {}\".format(adult_estimator.bhattacharyya_bound()))\n",
    "print(\"Nearest Neighbor upper bound: {}\".format(adult_estimator.nn_bound()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ALL INPUT FEATURES EXCEPT DEMOGRAHPICS ---\n",
      "Mahalanobis upper bound: 0.2384713446213045\n",
      "Bhattacharrya upper bound: (0.00015592896539001755, 0.012486178420467755)\n",
      "Nearest Neighbor upper bound: (0.11427999564988628, 0.20244015648829652)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = pickle.load(open('Data/adult_income/processed_data.pkl', 'rb'))\n",
    "X_train = X_train.drop(labels=['race_Other', 'race_Black', 'race_White', 'sex_Male'], axis=1)\n",
    "X = X_train[['capital-gain', 'capital-loss', 'hours-per-week', 'age', 'education-num']]\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "adult_estimator = BEREstimator(X_train, y_train)\n",
    "print(\"--- ALL INPUT FEATURES EXCEPT DEMOGRAHPICS ---\")\n",
    "print(\"Mahalanobis upper bound: {}\".format(adult_estimator.mahalanobis_bound()))\n",
    "print(\"Bhattacharrya upper bound: {}\".format(adult_estimator.bhattacharyya_bound()))\n",
    "print(\"Nearest Neighbor upper bound: {}\".format(adult_estimator.nn_bound()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DECOUPLED, ADULT INCOME ---\n",
      "----Decoupled Race-----\n",
      "(2817, 42) (2817,)\n",
      "BLACK\n",
      "\tMahalanobis upper bound: 0.14569061587948332\n",
      "\tBhattacharrya upper bound: (0.0, 0.0)\n",
      "\tNearest Neighbor upper bound: (0.06737175410286744, 0.12566560170394037)\n",
      "WHITE\n",
      "\tMahalanobis upper bound: 0.24947258980904832\n",
      "\tBhattacharrya upper bound: (0.0, 1.8233875173788025e-11)\n",
      "\tNearest Neighbor upper bound: (0.12015098579878503, 0.21142945282073033)\n",
      "\n",
      "-----Decoupled Sex-------\n",
      "FEMALE\n",
      "\tMahalanobis upper bound: 0.12883439717256787\n",
      "\tBhattacharrya upper bound: (0.0, 0.0)\n",
      "\tNearest Neighbor upper bound: (0.061022917265815824, 0.11459824166837047)\n",
      "MALE\n",
      "\tMahalanobis upper bound: 0.28570593841859737\n",
      "\tBhattacharrya upper bound: (0.0, 0.0)\n",
      "\tNearest Neighbor upper bound: (0.1443709356600102, 0.2470559371933268)\n"
     ]
    }
   ],
   "source": [
    "# for the different groups\n",
    "print(\"--- DECOUPLED, ADULT INCOME ---\")\n",
    "print(\"----Decoupled Race-----\")\n",
    "X_train, y_train, X_test, y_test = pickle.load(open('Data/adult_income/processed_data.pkl', 'rb'))\n",
    "X_train, y_train = X_train[X_train['race_Black']==1], y_train[X_train['race_Black']==1]\n",
    "X_test, y_test = X_test[X_test['race_Black']==1], y_test[X_test['race_Black']==1]\n",
    "X_train = X_train.drop(labels=['race_Black', 'race_Other', 'race_White', 'sex_Male', 'sex_Female'], axis=1)\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "adult_estimator = BEREstimator(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(\"BLACK\")\n",
    "print(\"\\tMahalanobis upper bound: {}\".format(adult_estimator.mahalanobis_bound()))\n",
    "print(\"\\tBhattacharrya upper bound: {}\".format(adult_estimator.bhattacharyya_bound()))\n",
    "print(\"\\tNearest Neighbor upper bound: {}\".format(adult_estimator.nn_bound()))\n",
    "\n",
    "X_train, y_train, X_test, y_test = pickle.load(open('Data/adult_income/processed_data.pkl', 'rb'))\n",
    "X_train, y_train = X_train[X_train['race_White']==1], y_train[X_train['race_White']==1]\n",
    "X_test, y_test = X_test[X_test['race_White']==1], y_test[X_test['race_White']==1]\n",
    "X_train = X_train.drop(labels=['race_Black', 'race_Other', 'race_White', 'sex_Male', 'sex_Female'], axis=1)\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "adult_estimator = BEREstimator(X_train, y_train)\n",
    "print(\"WHITE\")\n",
    "print(\"\\tMahalanobis upper bound: {}\".format(adult_estimator.mahalanobis_bound()))\n",
    "print(\"\\tBhattacharrya upper bound: {}\".format(adult_estimator.bhattacharyya_bound()))\n",
    "print(\"\\tNearest Neighbor upper bound: {}\".format(adult_estimator.nn_bound()))\n",
    "\n",
    "print()\n",
    "print(\"-----Decoupled Sex-------\")\n",
    "X_train, y_train, X_test, y_test = pickle.load(open('Data/adult_income/processed_data.pkl', 'rb'))\n",
    "X_train, y_train = X_train[X_train['sex_Male']==0], y_train[X_train['sex_Male']==0]\n",
    "X_test, y_test = X_test[X_test['sex_Male']==0], y_test[X_test['sex_Male']==0]\n",
    "X_train = X_train.drop(labels=['race_Black', 'race_Other', 'race_White', 'sex_Male', 'sex_Female'], axis=1)\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "adult_estimator = BEREstimator(X_train, y_train)\n",
    "print(\"FEMALE\")\n",
    "print(\"\\tMahalanobis upper bound: {}\".format(adult_estimator.mahalanobis_bound()))\n",
    "print(\"\\tBhattacharrya upper bound: {}\".format(adult_estimator.bhattacharyya_bound()))\n",
    "print(\"\\tNearest Neighbor upper bound: {}\".format(adult_estimator.nn_bound()))\n",
    "\n",
    "X_train, y_train, X_test, y_test = pickle.load(open('Data/adult_income/processed_data.pkl', 'rb'))\n",
    "X_train, y_train = X_train[X_train['sex_Male']==1], y_train[X_train['sex_Male']==1]\n",
    "X_test, y_test = X_test[X_test['sex_Male']==1], y_test[X_test['sex_Male']==1]\n",
    "X_train = X_train.drop(labels=['race_Black', 'race_Other', 'race_White', 'sex_Male', 'sex_Female'], axis=1)\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "adult_estimator = BEREstimator(X_train, y_train)\n",
    "print(\"MALE\")\n",
    "print(\"\\tMahalanobis upper bound: {}\".format(adult_estimator.mahalanobis_bound()))\n",
    "print(\"\\tBhattacharrya upper bound: {}\".format(adult_estimator.bhattacharyya_bound()))\n",
    "print(\"\\tNearest Neighbor upper bound: {}\".format(adult_estimator.nn_bound()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPAS Recidivism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ALL INPUT FEATURES INCLUDING DEMOGRAPHICS: VIOLENT CRIME ---\n",
      "Mahalanobis upper bound: 0.19586095536150863\n",
      "Bhattacharrya upper bound: (0.00010508635518702292, 0.010250624958750676)\n",
      "Nearest Neighbor upper bound: (0.0823570486352398, 0.15114873035066506)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = pickle.load(open('Data/compas/processed_violent_nonsingular.pkl', 'rb'))\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "violent_estimator = BEREstimator(X_train, y_train)\n",
    "print(\"--- ALL INPUT FEATURES INCLUDING DEMOGRAPHICS: VIOLENT CRIME ---\")\n",
    "print(\"Mahalanobis upper bound: {}\".format(violent_estimator.mahalanobis_bound()))\n",
    "print(\"Bhattacharrya upper bound: {}\".format(violent_estimator.bhattacharyya_bound()))\n",
    "print(\"Nearest Neighbor upper bound: {}\".format(violent_estimator.nn_bound()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ALL INPUT FEATURES EXCEPT DEMOGRAPHICS: VIOLENT CRIME ---\n",
      "Mahalanobis upper bound: 0.19647007198919228\n",
      "Bhattacharrya upper bound: (0.0, 9.418429699515122e-10)\n",
      "Nearest Neighbor upper bound: (0.06533241098704945, 0.12212817412333736)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = pickle.load(open('Data/compas/processed_violent_nonsingular.pkl', 'rb'))\n",
    "X_train = X_train.drop(columns=['race_is_causasian', 'race_is_african_american', 'race_is_hispanic', 'female'])\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "violent_estimator = BEREstimator(X_train, y_train)\n",
    "print(\"--- ALL INPUT FEATURES EXCEPT DEMOGRAPHICS: VIOLENT CRIME ---\")\n",
    "print(\"Mahalanobis upper bound: {}\".format(violent_estimator.mahalanobis_bound()))\n",
    "print(\"Bhattacharrya upper bound: {}\".format(violent_estimator.bhattacharyya_bound()))\n",
    "print(\"Nearest Neighbor upper bound: {}\".format(violent_estimator.nn_bound()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Decoupled Race-----\n",
      "\n",
      "BLACK\n",
      "\tMahalanobis upper bound: 0.23171405034927542\n",
      "\tBhattacharrya upper bound: (0.020318962310274413, 0.14108898639124204)\n",
      "\tNearest Neighbor upper bound: (0.08154451491172132, 0.14979001399906672)\n",
      "\n",
      "WHITE\n",
      "\tMahalanobis upper bound: 0.15323894932606172\n",
      "\tBhattacharrya upper bound: (0.0, 0.0)\n",
      "\tNearest Neighbor upper bound: (0.11003473331478347, 0.1958541815582559)\n",
      "\n",
      "-----Decoupled Sex-------\n",
      "\n",
      "FEMALE\n",
      "\tMahalanobis upper bound: 0.13330424601679006\n",
      "\tBhattacharrya upper bound: (nan, nan)\n",
      "\tNearest Neighbor upper bound: (0.06909816364635402, 0.1286472148541114)\n",
      "\n",
      "MALE\n",
      "\tMahalanobis upper bound: 0.20918503644901543\n",
      "\tBhattacharrya upper bound: (nan, nan)\n",
      "\tNearest Neighbor upper bound: (0.13955973551084727, 0.2401656314699793)\n"
     ]
    }
   ],
   "source": [
    "# for the different groups\n",
    "print(\"----Decoupled Race-----\")\n",
    "X_train, y_train, X_test, y_test = pickle.load(open('Data/compas/processed_violent_nonsingular.pkl', 'rb'))\n",
    "X_train, y_train = X_train[X_train['race_is_african_american']==1], y_train[X_train['race_is_african_american']==1]\n",
    "X_test, y_test = X_test[X_test['race_is_african_american']==1], y_test[X_test['race_is_african_american']==1]\n",
    "X_train = X_train.drop(labels=['race_is_causasian', 'race_is_african_american', 'race_is_hispanic', 'female'], axis=1)\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "compas_estimator = BEREstimator(X_train, y_train)\n",
    "print()\n",
    "print(\"BLACK\")\n",
    "print(\"\\tMahalanobis upper bound: {}\".format(compas_estimator.mahalanobis_bound()))\n",
    "print(\"\\tBhattacharrya upper bound: {}\".format(compas_estimator.bhattacharyya_bound()))\n",
    "print(\"\\tNearest Neighbor upper bound: {}\".format(compas_estimator.nn_bound()))\n",
    "\n",
    "\n",
    "X_train, y_train, X_test, y_test = pickle.load(open('Data/compas/processed_violent_nonsingular.pkl', 'rb'))\n",
    "X_train, y_train = X_train[X_train['race_is_causasian']==1], y_train[X_train['race_is_causasian']==1]\n",
    "X_test, y_test = X_test[X_test['race_is_causasian']==1], y_test[X_test['race_is_causasian']==1]\n",
    "X_train = X_train.drop(labels=['race_is_causasian', 'race_is_african_american', 'race_is_hispanic', 'female'], axis=1)\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "compas_estimator = BEREstimator(X_train, y_train)\n",
    "print()\n",
    "print(\"WHITE\")\n",
    "print(\"\\tMahalanobis upper bound: {}\".format(compas_estimator.mahalanobis_bound()))\n",
    "print(\"\\tBhattacharrya upper bound: {}\".format(compas_estimator.bhattacharyya_bound()))\n",
    "print(\"\\tNearest Neighbor upper bound: {}\".format(compas_estimator.nn_bound()))\n",
    "\n",
    "print()\n",
    "print(\"-----Decoupled Sex-------\")\n",
    "X_train, y_train, X_test, y_test = pickle.load(open('Data/compas/processed_violent_nonsingular.pkl', 'rb'))\n",
    "X_train, y_train = X_train[X_train['female']==1], y_train[X_train['female']==1]\n",
    "X_test, y_test = X_test[X_test['female']==1], y_test[X_test['female']==1]\n",
    "X_train = X_train.drop(labels=['race_is_causasian', 'race_is_african_american', 'race_is_hispanic', 'female'], axis=1)\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "compas_estimator = BEREstimator(X_train, y_train)\n",
    "print()\n",
    "print(\"FEMALE\")\n",
    "print(\"\\tMahalanobis upper bound: {}\".format(compas_estimator.mahalanobis_bound()))\n",
    "print(\"\\tBhattacharrya upper bound: {}\".format(compas_estimator.bhattacharyya_bound()))\n",
    "print(\"\\tNearest Neighbor upper bound: {}\".format(compas_estimator.nn_bound()))\n",
    "\n",
    "\n",
    "X_train, y_train, X_test, y_test = pickle.load(open('Data/compas/processed_violent_nonsingular.pkl', 'rb'))\n",
    "X_train, y_train = X_train[X_train['female']==0], y_train[X_train['female']==0]\n",
    "X_test, y_test = X_test[X_test['female']==0], y_test[X_test['female']==0]\n",
    "X_train = X_train.drop(labels=['race_is_causasian', 'race_is_african_american', 'race_is_hispanic', 'female'], axis=1)\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "compas_estimator = BEREstimator(X_train, y_train)\n",
    "print()\n",
    "print(\"MALE\")\n",
    "print(\"\\tMahalanobis upper bound: {}\".format(compas_estimator.mahalanobis_bound()))\n",
    "print(\"\\tBhattacharrya upper bound: {}\".format(compas_estimator.bhattacharyya_bound()))\n",
    "print(\"\\tNearest Neighbor upper bound: {}\".format(compas_estimator.nn_bound()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ALL INPUT FEATURES INCLUDING DEMOGRAPHICS: RE-ARREST ---\n",
      "Mahalanobis upper bound: 0.4223692451173532\n",
      "Bhattacharrya upper bound: (0.0, 0.0)\n",
      "Nearest Neighbor upper bound: (0.3235442308898998, 0.437726723095526)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = pickle.load(open('Data/compas/processed_arrest_nonsingular.pkl', 'rb'))\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "violent_estimator = BEREstimator(X_train, y_train)\n",
    "print(\"--- ALL INPUT FEATURES INCLUDING DEMOGRAPHICS: RE-ARREST ---\")\n",
    "print(\"Mahalanobis upper bound: {}\".format(violent_estimator.mahalanobis_bound()))\n",
    "print(\"Bhattacharrya upper bound: {}\".format(violent_estimator.bhattacharyya_bound()))\n",
    "print(\"Nearest Neighbor upper bound: {}\".format(violent_estimator.nn_bound()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ALL INPUT FEATURES EXCLUDING DEMOGRAPHICS: RE-ARREST ---\n",
      "Mahalanobis upper bound: 0.42518241798423584\n",
      "Bhattacharrya upper bound: (nan, nan)\n",
      "Nearest Neighbor upper bound: (0.28214522881031767, 0.40507859733978235)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = pickle.load(open('Data/compas/processed_arrest_nonsingular.pkl', 'rb'))\n",
    "X_train = X_train.drop(columns=['race_is_causasian', 'race_is_african_american', 'race_is_hispanic', 'female'])\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "violent_estimator = BEREstimator(X_train, y_train)\n",
    "print(\"--- ALL INPUT FEATURES EXCLUDING DEMOGRAPHICS: RE-ARREST ---\")\n",
    "print(\"Mahalanobis upper bound: {}\".format(violent_estimator.mahalanobis_bound()))\n",
    "print(\"Bhattacharrya upper bound: {}\".format(violent_estimator.bhattacharyya_bound()))\n",
    "print(\"Nearest Neighbor upper bound: {}\".format(violent_estimator.nn_bound()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Decoupled Race-----\n",
      "\n",
      "BLACK\n",
      "\tMahalanobis upper bound: 0.4286840162649842\n",
      "\tBhattacharrya upper bound: (0.0018098295397597775, 0.04250357698825829)\n",
      "\tNearest Neighbor upper bound: (0.4008563430739571, 0.48034107058266223)\n",
      "\n",
      "WHITE\n",
      "\tMahalanobis upper bound: 0.4233892364072617\n",
      "\tBhattacharrya upper bound: (0.0, 0.0)\n",
      "\tNearest Neighbor upper bound: (0.2877020430262899, 0.4098591549295775)\n",
      "-----Decoupled Sex-------\n",
      "\n",
      "FEMALE\n",
      "\tMahalanobis upper bound: 0.3878514393076384\n",
      "\tBhattacharrya upper bound: (0.0, 0.0)\n",
      "\tNearest Neighbor upper bound: (0.25340151904196406, 0.3783783783783784)\n",
      "\n",
      "MALE\n",
      "\tMahalanobis upper bound: 0.42946490529994935\n",
      "\tBhattacharrya upper bound: (0.0, 0.0)\n",
      "\tNearest Neighbor upper bound: (0.34468901876110336, 0.4517569982132222)\n"
     ]
    }
   ],
   "source": [
    "# for the different groups\n",
    "print(\"----Decoupled Race-----\")\n",
    "X_train, y_train, X_test, y_test = pickle.load(open('Data/compas/processed_arrest_nonsingular.pkl', 'rb'))\n",
    "X_train, y_train = X_train[X_train['race_is_african_american']==1], y_train[X_train['race_is_african_american']==1]\n",
    "X_test, y_test = X_test[X_test['race_is_african_american']==1], y_test[X_test['race_is_african_american']==1]\n",
    "X_train = X_train.drop(labels=['race_is_causasian', 'race_is_african_american', 'race_is_hispanic', 'female'], axis=1)\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "compas_estimator = BEREstimator(X_train, y_train)\n",
    "print()\n",
    "print(\"BLACK\")\n",
    "print(\"\\tMahalanobis upper bound: {}\".format(compas_estimator.mahalanobis_bound()))\n",
    "print(\"\\tBhattacharrya upper bound: {}\".format(compas_estimator.bhattacharyya_bound()))\n",
    "print(\"\\tNearest Neighbor upper bound: {}\".format(compas_estimator.nn_bound()))\n",
    "\n",
    "\n",
    "X_train, y_train, X_test, y_test = pickle.load(open('Data/compas/processed_arrest_nonsingular.pkl', 'rb'))\n",
    "X_train, y_train = X_train[X_train['race_is_causasian']==1], y_train[X_train['race_is_causasian']==1]\n",
    "X_test, y_test = X_test[X_test['race_is_causasian']==1], y_test[X_test['race_is_causasian']==1]\n",
    "X_train = X_train.drop(labels=['race_is_causasian', 'race_is_african_american', 'race_is_hispanic', 'female'], axis=1)\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "compas_estimator = BEREstimator(X_train, y_train)\n",
    "print()\n",
    "print(\"WHITE\")\n",
    "print(\"\\tMahalanobis upper bound: {}\".format(compas_estimator.mahalanobis_bound()))\n",
    "print(\"\\tBhattacharrya upper bound: {}\".format(compas_estimator.bhattacharyya_bound()))\n",
    "print(\"\\tNearest Neighbor upper bound: {}\".format(compas_estimator.nn_bound()))\n",
    "\n",
    "print(\"-----Decoupled Sex-------\")\n",
    "X_train, y_train, X_test, y_test = pickle.load(open('Data/compas/processed_arrest_nonsingular.pkl', 'rb'))\n",
    "X_train, y_train = X_train[X_train['female']==1], y_train[X_train['female']==1]\n",
    "X_test, y_test = X_test[X_test['female']==1], y_test[X_test['female']==1]\n",
    "X_train = X_train.drop(labels=['race_is_causasian', 'race_is_african_american', 'race_is_hispanic', 'female'], axis=1)\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "compas_estimator = BEREstimator(X_train, y_train)\n",
    "print()\n",
    "print(\"FEMALE\")\n",
    "print(\"\\tMahalanobis upper bound: {}\".format(compas_estimator.mahalanobis_bound()))\n",
    "print(\"\\tBhattacharrya upper bound: {}\".format(compas_estimator.bhattacharyya_bound()))\n",
    "print(\"\\tNearest Neighbor upper bound: {}\".format(compas_estimator.nn_bound()))\n",
    "\n",
    "\n",
    "X_train, y_train, X_test, y_test = pickle.load(open('Data/compas/processed_arrest_nonsingular.pkl', 'rb'))\n",
    "X_train, y_train = X_train[X_train['female']==0], y_train[X_train['female']==0]\n",
    "X_test, y_test = X_test[X_test['female']==0], y_test[X_test['female']==0]\n",
    "X_train = X_train.drop(labels=['race_is_causasian', 'race_is_african_american', 'race_is_hispanic', 'female'], axis=1)\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "compas_estimator = BEREstimator(X_train, y_train)\n",
    "print()\n",
    "print(\"MALE\")\n",
    "print(\"\\tMahalanobis upper bound: {}\".format(compas_estimator.mahalanobis_bound()))\n",
    "print(\"\\tBhattacharrya upper bound: {}\".format(compas_estimator.bhattacharyya_bound()))\n",
    "print(\"\\tNearest Neighbor upper bound: {}\".format(compas_estimator.nn_bound()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIMIC-III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../mimic_dataset.pkl\"\n",
    "data = pickle.load(open(path, 'rb'))\n",
    "X_train, y_train, X_test, y_test = data['train_test_split']\n",
    "\n",
    "X_train = X_train.drop(columns=['IS_SEX_M', 'IS_RACE_BLACK', 'IS_RACE_WHITE', 'IS_RACE_HISPANIC', 'IS_RACE_ASIAN', 'IS_SEX_F'], axis=1)\n",
    "# X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "# mimic_estimator = BEREstimator(X_train, y_train)\n",
    "# print(\"--- ALL INPUT FEATURES (MIMIC-III) ---\")\n",
    "# print(\"Mahalanobis upper bound: {}\".format(mimic_estimator.mahalanobis_bound()))\n",
    "# print(\"Bhattacharrya upper bound: {}\".format(mimic_estimator.bhattacharyya_bound()))\n",
    "# print(\"Nearest Neighbor upper bound: {}\".format(mimic_estimator.nn_bound()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use the '.sparse' accessor with Sparse data.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8fe30295c5d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_coo_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5178\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/accessor.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;31m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0maccessor_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;31m# Replace the property with the accessor object. Inspired by:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;31m# http://www.pydanny.com/cached-property.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/arrays/sparse.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1955\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1956\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1957\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/arrays/sparse.py\u001b[0m in \u001b[0;36m_validate\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   2132\u001b[0m         \u001b[0mdtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSparseDtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2134\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validation_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2136\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use the '.sparse' accessor with Sparse data."
     ]
    }
   ],
   "source": [
    "data['dataset'].sparse.to_coo_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "svd = TruncatedSVD(n_components=15, random_state=42)\n",
    "data = svd.fit_transform(X_train) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
