{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ber_metrics import BEREstimator\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from collections import defaultdict\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_estimates(load_path, save_path, black_key, white_key, female_key, drop_cols=[]):\n",
    "    X_train, y_train, X_test, y_test = pickle.load(open(load_path, 'rb'))\n",
    "    xtrain, ytrain, xtest, ytest = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "    estimator = BEREstimator(xtrain, ytrain)\n",
    "    estimates = defaultdict(dict)\n",
    "    estimates['maha']['all_with_demographic'] = estimator.mahalanobis_bound()\n",
    "    estimates['bhatt']['all_with_demographic'] = estimator.bhattacharyya_bound()\n",
    "    estimates['nn']['all_with_demographic'] = estimator.nn_bound()\n",
    "    \n",
    "    # no protected features\n",
    "    xtrain = np.array(X_train.drop(labels=drop_cols, axis=1))\n",
    "    estimator = BEREstimator(xtrain, ytrain)\n",
    "    estimates['maha']['all_no_demographic'] = estimator.mahalanobis_bound()\n",
    "    estimates['bhatt']['all_no_demographic'] = estimator.bhattacharyya_bound()\n",
    "    estimates['nn']['all_no_demographic'] = estimator.nn_bound()\n",
    "    \n",
    "    # black\n",
    "    xtrain, ytrain = np.array(X_train[X_train[black_key]==1].drop(labels=drop_cols, axis=1)), np.array(y_train[X_train[black_key ]==1])\n",
    "    estimator = BEREstimator(xtrain, ytrain)\n",
    "    estimates['maha']['black'] = estimator.mahalanobis_bound()\n",
    "    estimates['bhatt']['black'] = estimator.bhattacharyya_bound()\n",
    "    estimates['nn']['black'] = estimator.nn_bound()\n",
    "    \n",
    "    # white\n",
    "    xtrain, ytrain = np.array(X_train[X_train[white_key]==1].drop(labels=drop_cols, axis=1)), np.array(y_train[X_train[white_key]==1])\n",
    "    estimator = BEREstimator(xtrain, ytrain)\n",
    "    estimates['maha']['white'] = estimator.mahalanobis_bound()\n",
    "    estimates['bhatt']['white'] = estimator.bhattacharyya_bound()\n",
    "    estimates['nn']['white'] = estimator.nn_bound()\n",
    "    \n",
    "    # female\n",
    "    xtrain, ytrain = np.array(X_train[X_train[female_key]==1].drop(labels=drop_cols, axis=1)), np.array(y_train[X_train[female_key]==1])\n",
    "    estimator = BEREstimator(xtrain, ytrain)\n",
    "    estimates['maha']['female'] = estimator.mahalanobis_bound()\n",
    "    estimates['bhatt']['female'] = estimator.bhattacharyya_bound()\n",
    "    estimates['nn']['female'] = estimator.nn_bound()\n",
    "    \n",
    "    # male\n",
    "    xtrain, ytrain = np.array(X_train[X_train[female_key]==0].drop(labels=drop_cols, axis=1)), np.array(y_train[X_train[female_key]==0])\n",
    "    estimator = BEREstimator(xtrain, ytrain)\n",
    "    estimates['maha']['male'] = estimator.mahalanobis_bound()\n",
    "    estimates['bhatt']['male'] = estimator.bhattacharyya_bound()\n",
    "    estimates['nn']['male'] = estimator.nn_bound()\n",
    "    \n",
    "    pickle.dump(estimates, open(save_path, \"wb\"))\n",
    "    pprint.pprint(estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adult Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ALL INPUT FEATURES INCLUDING PROTECTED VARS ---\n",
      "Mahalanobis upper bound: 0.2383977285329773\n",
      "Bhattacharrya upper bound: (0.00018925250028173357, 0.01375560554002971)\n",
      "Nearest Neighbor upper bound: (0.11550679563529465, 0.20432995159472184)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = pickle.load(open('Data/adult_income/processed_data.pkl', 'rb'))\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "adult_estimator = BEREstimator(X_train, y_train)\n",
    "print(\"--- ALL INPUT FEATURES INCLUDING PROTECTED VARS ---\")\n",
    "print(\"Mahalanobis upper bound: {}\".format(adult_estimator.mahalanobis_bound()))\n",
    "print(\"Bhattacharrya upper bound: {}\".format(adult_estimator.bhattacharyya_bound()))\n",
    "print(\"Nearest Neighbor upper bound: {}\".format(adult_estimator.nn_bound()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ALL INPUT FEATURES EXCEPT DEMOGRAHPICS ---\n",
      "Mahalanobis upper bound: 0.23958132853260622\n",
      "Bhattacharrya upper bound: (0.006264390495551109, 0.07889960650897043)\n",
      "Nearest Neighbor upper bound: (0.11406516967703556, 0.2021086134871693)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = pickle.load(open('Data/adult_income/processed_data.pkl', 'rb'))\n",
    "X_train = X_train.drop(labels=['race_Other', 'race_Black', 'race_White', 'sex_Male', 'sex_Female'], axis=1)\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "adult_estimator = BEREstimator(X_train, y_train)\n",
    "print(\"--- ALL INPUT FEATURES EXCEPT DEMOGRAHPICS ---\")\n",
    "print(\"Mahalanobis upper bound: {}\".format(adult_estimator.mahalanobis_bound()))\n",
    "print(\"Bhattacharrya upper bound: {}\".format(adult_estimator.bhattacharyya_bound()))\n",
    "print(\"Nearest Neighbor upper bound: {}\".format(adult_estimator.nn_bound()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DECOUPLED, ADULT INCOME ---\n",
      "----Decoupled Race-----\n",
      "(2817, 42) (2817,)\n",
      "BLACK\n",
      "\tMahalanobis upper bound: 0.14569061587948332\n",
      "\tBhattacharrya upper bound: (0.0, 0.0)\n",
      "\tNearest Neighbor upper bound: (0.06737175410286744, 0.12566560170394037)\n",
      "WHITE\n",
      "\tMahalanobis upper bound: 0.24947258980904832\n",
      "\tBhattacharrya upper bound: (0.0, 1.8233875173788025e-11)\n",
      "\tNearest Neighbor upper bound: (0.12015098579878503, 0.21142945282073033)\n",
      "\n",
      "-----Decoupled Sex-------\n",
      "FEMALE\n",
      "\tMahalanobis upper bound: 0.12883439717256787\n",
      "\tBhattacharrya upper bound: (0.0, 0.0)\n",
      "\tNearest Neighbor upper bound: (0.061022917265815824, 0.11459824166837047)\n",
      "MALE\n",
      "\tMahalanobis upper bound: 0.28570593841859737\n",
      "\tBhattacharrya upper bound: (0.0, 0.0)\n",
      "\tNearest Neighbor upper bound: (0.1443709356600102, 0.2470559371933268)\n"
     ]
    }
   ],
   "source": [
    "# for the different groups\n",
    "print(\"--- DECOUPLED, ADULT INCOME ---\")\n",
    "print(\"----Decoupled Race-----\")\n",
    "X_train, y_train, X_test, y_test = pickle.load(open('Data/adult_income/processed_data.pkl', 'rb'))\n",
    "X_train, y_train = X_train[X_train['race_Black']==1], y_train[X_train['race_Black']==1]\n",
    "X_test, y_test = X_test[X_test['race_Black']==1], y_test[X_test['race_Black']==1]\n",
    "X_train = X_train.drop(labels=['race_Black', 'race_Other', 'race_White', 'sex_Male', 'sex_Female'], axis=1)\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "adult_estimator = BEREstimator(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(\"BLACK\")\n",
    "print(\"\\tMahalanobis upper bound: {}\".format(adult_estimator.mahalanobis_bound()))\n",
    "print(\"\\tBhattacharrya upper bound: {}\".format(adult_estimator.bhattacharyya_bound()))\n",
    "print(\"\\tNearest Neighbor upper bound: {}\".format(adult_estimator.nn_bound()))\n",
    "\n",
    "X_train, y_train, X_test, y_test = pickle.load(open('Data/adult_income/processed_data.pkl', 'rb'))\n",
    "X_train, y_train = X_train[X_train['race_White']==1], y_train[X_train['race_White']==1]\n",
    "X_test, y_test = X_test[X_test['race_White']==1], y_test[X_test['race_White']==1]\n",
    "X_train = X_train.drop(labels=['race_Black', 'race_Other', 'race_White', 'sex_Male', 'sex_Female'], axis=1)\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "adult_estimator = BEREstimator(X_train, y_train)\n",
    "print(\"WHITE\")\n",
    "print(\"\\tMahalanobis upper bound: {}\".format(adult_estimator.mahalanobis_bound()))\n",
    "print(\"\\tBhattacharrya upper bound: {}\".format(adult_estimator.bhattacharyya_bound()))\n",
    "print(\"\\tNearest Neighbor upper bound: {}\".format(adult_estimator.nn_bound()))\n",
    "\n",
    "print()\n",
    "print(\"-----Decoupled Sex-------\")\n",
    "X_train, y_train, X_test, y_test = pickle.load(open('Data/adult_income/processed_data.pkl', 'rb'))\n",
    "X_train, y_train = X_train[X_train['sex_Male']==0], y_train[X_train['sex_Male']==0]\n",
    "X_test, y_test = X_test[X_test['sex_Male']==0], y_test[X_test['sex_Male']==0]\n",
    "X_train = X_train.drop(labels=['race_Black', 'race_Other', 'race_White', 'sex_Male', 'sex_Female'], axis=1)\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "adult_estimator = BEREstimator(X_train, y_train)\n",
    "print(\"FEMALE\")\n",
    "print(\"\\tMahalanobis upper bound: {}\".format(adult_estimator.mahalanobis_bound()))\n",
    "print(\"\\tBhattacharrya upper bound: {}\".format(adult_estimator.bhattacharyya_bound()))\n",
    "print(\"\\tNearest Neighbor upper bound: {}\".format(adult_estimator.nn_bound()))\n",
    "\n",
    "X_train, y_train, X_test, y_test = pickle.load(open('Data/adult_income/processed_data.pkl', 'rb'))\n",
    "X_train, y_train = X_train[X_train['sex_Male']==1], y_train[X_train['sex_Male']==1]\n",
    "X_test, y_test = X_test[X_test['sex_Male']==1], y_test[X_test['sex_Male']==1]\n",
    "X_train = X_train.drop(labels=['race_Black', 'race_Other', 'race_White', 'sex_Male', 'sex_Female'], axis=1)\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "adult_estimator = BEREstimator(X_train, y_train)\n",
    "print(\"MALE\")\n",
    "print(\"\\tMahalanobis upper bound: {}\".format(adult_estimator.mahalanobis_bound()))\n",
    "print(\"\\tBhattacharrya upper bound: {}\".format(adult_estimator.bhattacharyya_bound()))\n",
    "print(\"\\tNearest Neighbor upper bound: {}\".format(adult_estimator.nn_bound()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPAS Recidivism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ALL INPUT FEATURES INCLUDING DEMOGRAPHICS: VIOLENT CRIME ---\n",
      "Mahalanobis upper bound: 0.19586095536150863\n",
      "Bhattacharrya upper bound: (0.00010508635518702292, 0.010250624958750676)\n",
      "Nearest Neighbor upper bound: (0.0823570486352398, 0.15114873035066506)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = pickle.load(open('Data/compas/processed_violent_nonsingular.pkl', 'rb'))\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "violent_estimator = BEREstimator(X_train, y_train)\n",
    "print(\"--- ALL INPUT FEATURES INCLUDING DEMOGRAPHICS: VIOLENT CRIME ---\")\n",
    "print(\"Mahalanobis upper bound: {}\".format(violent_estimator.mahalanobis_bound()))\n",
    "print(\"Bhattacharrya upper bound: {}\".format(violent_estimator.bhattacharyya_bound()))\n",
    "print(\"Nearest Neighbor upper bound: {}\".format(violent_estimator.nn_bound()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ALL INPUT FEATURES EXCEPT DEMOGRAPHICS: VIOLENT CRIME ---\n",
      "Mahalanobis upper bound: 0.19647007198919228\n",
      "Bhattacharrya upper bound: (0.0, 9.418429699515122e-10)\n",
      "Nearest Neighbor upper bound: (0.06533241098704945, 0.12212817412333736)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = pickle.load(open('Data/compas/processed_violent_nonsingular.pkl', 'rb'))\n",
    "X_train = X_train.drop(columns=['race_is_causasian', 'race_is_african_american', 'race_is_hispanic', 'female'])\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "violent_estimator = BEREstimator(X_train, y_train)\n",
    "print(\"--- ALL INPUT FEATURES EXCEPT DEMOGRAPHICS: VIOLENT CRIME ---\")\n",
    "print(\"Mahalanobis upper bound: {}\".format(violent_estimator.mahalanobis_bound()))\n",
    "print(\"Bhattacharrya upper bound: {}\".format(violent_estimator.bhattacharyya_bound()))\n",
    "print(\"Nearest Neighbor upper bound: {}\".format(violent_estimator.nn_bound()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Decoupled Race-----\n",
      "\n",
      "BLACK\n",
      "\tMahalanobis upper bound: 0.23171405034927542\n",
      "\tBhattacharrya upper bound: (0.020318962310274413, 0.14108898639124204)\n",
      "\tNearest Neighbor upper bound: (0.08154451491172132, 0.14979001399906672)\n",
      "\n",
      "WHITE\n",
      "\tMahalanobis upper bound: 0.15323894932606172\n",
      "\tBhattacharrya upper bound: (0.0, 0.0)\n",
      "\tNearest Neighbor upper bound: (0.11003473331478347, 0.1958541815582559)\n",
      "\n",
      "-----Decoupled Sex-------\n",
      "\n",
      "FEMALE\n",
      "\tMahalanobis upper bound: 0.13330424601679006\n",
      "\tBhattacharrya upper bound: (nan, nan)\n",
      "\tNearest Neighbor upper bound: (0.06909816364635402, 0.1286472148541114)\n",
      "\n",
      "MALE\n",
      "\tMahalanobis upper bound: 0.20918503644901543\n",
      "\tBhattacharrya upper bound: (nan, nan)\n",
      "\tNearest Neighbor upper bound: (0.13955973551084727, 0.2401656314699793)\n"
     ]
    }
   ],
   "source": [
    "# for the different groups\n",
    "print(\"----Decoupled Race-----\")\n",
    "X_train, y_train, X_test, y_test = pickle.load(open('Data/compas/processed_violent_nonsingular.pkl', 'rb'))\n",
    "X_train, y_train = X_train[X_train['race_is_african_american']==1], y_train[X_train['race_is_african_american']==1]\n",
    "X_test, y_test = X_test[X_test['race_is_african_american']==1], y_test[X_test['race_is_african_american']==1]\n",
    "X_train = X_train.drop(labels=['race_is_causasian', 'race_is_african_american', 'race_is_hispanic', 'female'], axis=1)\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "compas_estimator = BEREstimator(X_train, y_train)\n",
    "print()\n",
    "print(\"BLACK\")\n",
    "print(\"\\tMahalanobis upper bound: {}\".format(compas_estimator.mahalanobis_bound()))\n",
    "print(\"\\tBhattacharrya upper bound: {}\".format(compas_estimator.bhattacharyya_bound()))\n",
    "print(\"\\tNearest Neighbor upper bound: {}\".format(compas_estimator.nn_bound()))\n",
    "\n",
    "\n",
    "X_train, y_train, X_test, y_test = pickle.load(open('Data/compas/processed_violent_nonsingular.pkl', 'rb'))\n",
    "X_train, y_train = X_train[X_train['race_is_causasian']==1], y_train[X_train['race_is_causasian']==1]\n",
    "X_test, y_test = X_test[X_test['race_is_causasian']==1], y_test[X_test['race_is_causasian']==1]\n",
    "X_train = X_train.drop(labels=['race_is_causasian', 'race_is_african_american', 'race_is_hispanic', 'female'], axis=1)\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "compas_estimator = BEREstimator(X_train, y_train)\n",
    "print()\n",
    "print(\"WHITE\")\n",
    "print(\"\\tMahalanobis upper bound: {}\".format(compas_estimator.mahalanobis_bound()))\n",
    "print(\"\\tBhattacharrya upper bound: {}\".format(compas_estimator.bhattacharyya_bound()))\n",
    "print(\"\\tNearest Neighbor upper bound: {}\".format(compas_estimator.nn_bound()))\n",
    "\n",
    "print()\n",
    "print(\"-----Decoupled Sex-------\")\n",
    "X_train, y_train, X_test, y_test = pickle.load(open('Data/compas/processed_violent_nonsingular.pkl', 'rb'))\n",
    "X_train, y_train = X_train[X_train['female']==1], y_train[X_train['female']==1]\n",
    "X_test, y_test = X_test[X_test['female']==1], y_test[X_test['female']==1]\n",
    "X_train = X_train.drop(labels=['race_is_causasian', 'race_is_african_american', 'race_is_hispanic', 'female'], axis=1)\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "compas_estimator = BEREstimator(X_train, y_train)\n",
    "print()\n",
    "print(\"FEMALE\")\n",
    "print(\"\\tMahalanobis upper bound: {}\".format(compas_estimator.mahalanobis_bound()))\n",
    "print(\"\\tBhattacharrya upper bound: {}\".format(compas_estimator.bhattacharyya_bound()))\n",
    "print(\"\\tNearest Neighbor upper bound: {}\".format(compas_estimator.nn_bound()))\n",
    "\n",
    "\n",
    "X_train, y_train, X_test, y_test = pickle.load(open('Data/compas/processed_violent_nonsingular.pkl', 'rb'))\n",
    "X_train, y_train = X_train[X_train['female']==0], y_train[X_train['female']==0]\n",
    "X_test, y_test = X_test[X_test['female']==0], y_test[X_test['female']==0]\n",
    "X_train = X_train.drop(labels=['race_is_causasian', 'race_is_african_american', 'race_is_hispanic', 'female'], axis=1)\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "compas_estimator = BEREstimator(X_train, y_train)\n",
    "print()\n",
    "print(\"MALE\")\n",
    "print(\"\\tMahalanobis upper bound: {}\".format(compas_estimator.mahalanobis_bound()))\n",
    "print(\"\\tBhattacharrya upper bound: {}\".format(compas_estimator.bhattacharyya_bound()))\n",
    "print(\"\\tNearest Neighbor upper bound: {}\".format(compas_estimator.nn_bound()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ALL INPUT FEATURES INCLUDING DEMOGRAPHICS: RE-ARREST ---\n",
      "Mahalanobis upper bound: 0.4223692451173532\n",
      "Bhattacharrya upper bound: (0.0, 0.0)\n",
      "Nearest Neighbor upper bound: (0.3235442308898998, 0.437726723095526)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = pickle.load(open('Data/compas/processed_arrest_nonsingular.pkl', 'rb'))\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "violent_estimator = BEREstimator(X_train, y_train)\n",
    "print(\"--- ALL INPUT FEATURES INCLUDING DEMOGRAPHICS: RE-ARREST ---\")\n",
    "print(\"Mahalanobis upper bound: {}\".format(violent_estimator.mahalanobis_bound()))\n",
    "print(\"Bhattacharrya upper bound: {}\".format(violent_estimator.bhattacharyya_bound()))\n",
    "print(\"Nearest Neighbor upper bound: {}\".format(violent_estimator.nn_bound()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ALL INPUT FEATURES EXCLUDING DEMOGRAPHICS: RE-ARREST ---\n",
      "Mahalanobis upper bound: 0.42518241798423584\n",
      "Bhattacharrya upper bound: (nan, nan)\n",
      "Nearest Neighbor upper bound: (0.28214522881031767, 0.40507859733978235)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = pickle.load(open('Data/compas/processed_arrest_nonsingular.pkl', 'rb'))\n",
    "X_train = X_train.drop(columns=['race_is_causasian', 'race_is_african_american', 'race_is_hispanic', 'female'])\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "violent_estimator = BEREstimator(X_train, y_train)\n",
    "print(\"--- ALL INPUT FEATURES EXCLUDING DEMOGRAPHICS: RE-ARREST ---\")\n",
    "print(\"Mahalanobis upper bound: {}\".format(violent_estimator.mahalanobis_bound()))\n",
    "print(\"Bhattacharrya upper bound: {}\".format(violent_estimator.bhattacharyya_bound()))\n",
    "print(\"Nearest Neighbor upper bound: {}\".format(violent_estimator.nn_bound()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Decoupled Race-----\n",
      "\n",
      "BLACK\n",
      "\tMahalanobis upper bound: 0.4286840162649842\n",
      "\tBhattacharrya upper bound: (0.0018098295397597775, 0.04250357698825829)\n",
      "\tNearest Neighbor upper bound: (0.4008563430739571, 0.48034107058266223)\n",
      "\n",
      "WHITE\n",
      "\tMahalanobis upper bound: 0.4233892364072617\n",
      "\tBhattacharrya upper bound: (0.0, 0.0)\n",
      "\tNearest Neighbor upper bound: (0.2877020430262899, 0.4098591549295775)\n",
      "-----Decoupled Sex-------\n",
      "\n",
      "FEMALE\n",
      "\tMahalanobis upper bound: 0.3878514393076384\n",
      "\tBhattacharrya upper bound: (0.0, 0.0)\n",
      "\tNearest Neighbor upper bound: (0.25340151904196406, 0.3783783783783784)\n",
      "\n",
      "MALE\n",
      "\tMahalanobis upper bound: 0.42946490529994935\n",
      "\tBhattacharrya upper bound: (0.0, 0.0)\n",
      "\tNearest Neighbor upper bound: (0.34468901876110336, 0.4517569982132222)\n"
     ]
    }
   ],
   "source": [
    "# for the different groups\n",
    "print(\"----Decoupled Race-----\")\n",
    "X_train, y_train, X_test, y_test = pickle.load(open('Data/compas/processed_arrest_nonsingular.pkl', 'rb'))\n",
    "X_train, y_train = X_train[X_train['race_is_african_american']==1], y_train[X_train['race_is_african_american']==1]\n",
    "X_test, y_test = X_test[X_test['race_is_african_american']==1], y_test[X_test['race_is_african_american']==1]\n",
    "X_train = X_train.drop(labels=['race_is_causasian', 'race_is_african_american', 'race_is_hispanic', 'female'], axis=1)\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "compas_estimator = BEREstimator(X_train, y_train)\n",
    "print()\n",
    "print(\"BLACK\")\n",
    "print(\"\\tMahalanobis upper bound: {}\".format(compas_estimator.mahalanobis_bound()))\n",
    "print(\"\\tBhattacharrya upper bound: {}\".format(compas_estimator.bhattacharyya_bound()))\n",
    "print(\"\\tNearest Neighbor upper bound: {}\".format(compas_estimator.nn_bound()))\n",
    "\n",
    "\n",
    "X_train, y_train, X_test, y_test = pickle.load(open('Data/compas/processed_arrest_nonsingular.pkl', 'rb'))\n",
    "X_train, y_train = X_train[X_train['race_is_causasian']==1], y_train[X_train['race_is_causasian']==1]\n",
    "X_test, y_test = X_test[X_test['race_is_causasian']==1], y_test[X_test['race_is_causasian']==1]\n",
    "X_train = X_train.drop(labels=['race_is_causasian', 'race_is_african_american', 'race_is_hispanic', 'female'], axis=1)\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "compas_estimator = BEREstimator(X_train, y_train)\n",
    "print()\n",
    "print(\"WHITE\")\n",
    "print(\"\\tMahalanobis upper bound: {}\".format(compas_estimator.mahalanobis_bound()))\n",
    "print(\"\\tBhattacharrya upper bound: {}\".format(compas_estimator.bhattacharyya_bound()))\n",
    "print(\"\\tNearest Neighbor upper bound: {}\".format(compas_estimator.nn_bound()))\n",
    "\n",
    "print(\"-----Decoupled Sex-------\")\n",
    "X_train, y_train, X_test, y_test = pickle.load(open('Data/compas/processed_arrest_nonsingular.pkl', 'rb'))\n",
    "X_train, y_train = X_train[X_train['female']==1], y_train[X_train['female']==1]\n",
    "X_test, y_test = X_test[X_test['female']==1], y_test[X_test['female']==1]\n",
    "X_train = X_train.drop(labels=['race_is_causasian', 'race_is_african_american', 'race_is_hispanic', 'female'], axis=1)\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "compas_estimator = BEREstimator(X_train, y_train)\n",
    "print()\n",
    "print(\"FEMALE\")\n",
    "print(\"\\tMahalanobis upper bound: {}\".format(compas_estimator.mahalanobis_bound()))\n",
    "print(\"\\tBhattacharrya upper bound: {}\".format(compas_estimator.bhattacharyya_bound()))\n",
    "print(\"\\tNearest Neighbor upper bound: {}\".format(compas_estimator.nn_bound()))\n",
    "\n",
    "\n",
    "X_train, y_train, X_test, y_test = pickle.load(open('Data/compas/processed_arrest_nonsingular.pkl', 'rb'))\n",
    "X_train, y_train = X_train[X_train['female']==0], y_train[X_train['female']==0]\n",
    "X_test, y_test = X_test[X_test['female']==0], y_test[X_test['female']==0]\n",
    "X_train = X_train.drop(labels=['race_is_causasian', 'race_is_african_american', 'race_is_hispanic', 'female'], axis=1)\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "compas_estimator = BEREstimator(X_train, y_train)\n",
    "print()\n",
    "print(\"MALE\")\n",
    "print(\"\\tMahalanobis upper bound: {}\".format(compas_estimator.mahalanobis_bound()))\n",
    "print(\"\\tBhattacharrya upper bound: {}\".format(compas_estimator.bhattacharyya_bound()))\n",
    "print(\"\\tNearest Neighbor upper bound: {}\".format(compas_estimator.nn_bound()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIMIC-III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([                 0,                  1,                  2,\n",
      "                        3,                  4,                  5,\n",
      "                        6,                  7,                  8,\n",
      "                        9,                 10,                 11,\n",
      "                       12,                 13,                 14,\n",
      "                       15,                 16,                 17,\n",
      "                       18,                 19,                 20,\n",
      "                       21,                 22,                 23,\n",
      "                       24,                 25,                 26,\n",
      "                       27,                 28,                 29,\n",
      "                       30,                 31,                 32,\n",
      "                       33,                 34,                 35,\n",
      "                       36,                 37,                 38,\n",
      "                       39,         'IS_SEX_M',       'SUBJECT_ID',\n",
      "          'IS_RACE_BLACK',    'IS_RACE_WHITE', 'IS_RACE_HISPANIC',\n",
      "          'IS_RACE_ASIAN',    'IS_RACE_OTHER',         'IS_SEX_F'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "path = \"../mimic_compressed.pkl\"\n",
    "X_train, X_test, y_train, y_test = pickle.load(open(path, 'rb'))\n",
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ALL INPUT FEATURES (MIMIC-III) ---\n",
      "Mahalanobis upper bound: 3.2936672086581615e-06\n",
      "Bhattacharrya upper bound: (5.6900736372267335e-05, 0.007543043064869066)\n",
      "Nearest Neighbor upper bound: (0.02357718593308067, 0.04604260447311523)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = pickle.load(open(path, 'rb'))\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "mimic_estimator = BEREstimator(X_train, y_train)\n",
    "print(\"--- ALL INPUT FEATURES (MIMIC-III) ---\")\n",
    "print(\"Mahalanobis upper bound: {}\".format(mimic_estimator.mahalanobis_bound()))\n",
    "print(\"Bhattacharrya upper bound: {}\".format(mimic_estimator.bhattacharyya_bound()))\n",
    "print(\"Nearest Neighbor upper bound: {}\".format(mimic_estimator.nn_bound()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ALL INPUT FEATURES (MIMIC-III) ---\n",
      "Mahalanobis upper bound: 3.2998323778607902e-06\n",
      "Bhattacharrya upper bound: (6.879598411496657e-05, 0.008294049145473577)\n",
      "Nearest Neighbor upper bound: (0.014275311838182647, 0.02814305462021054)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = pickle.load(open(path, 'rb'))\n",
    "X_train = X_train.drop(columns=['IS_SEX_M', 'IS_RACE_BLACK', 'IS_RACE_WHITE', 'IS_RACE_HISPANIC', 'IS_RACE_ASIAN', 'IS_SEX_F'], axis=1)\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "mimic_estimator = BEREstimator(X_train, y_train)\n",
    "print(\"--- ALL INPUT FEATURES (MIMIC-III) ---\")\n",
    "print(\"Mahalanobis upper bound: {}\".format(mimic_estimator.mahalanobis_bound()))\n",
    "print(\"Bhattacharrya upper bound: {}\".format(mimic_estimator.bhattacharyya_bound()))\n",
    "print(\"Nearest Neighbor upper bound: {}\".format(mimic_estimator.nn_bound()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Decoupled Race-----\n",
      "\n",
      "BLACK\n",
      "\tMahalanobis upper bound: 3.15407309387005e-06\n",
      "\tBhattacharrya upper bound: (3.046635292675015e-05, 0.005519549322914704)\n",
      "\tNearest Neighbor upper bound: (0.03252170221056294, 0.06292808219178082)\n",
      "\n",
      "WHITE\n",
      "\tMahalanobis upper bound: 3.440601729633301e-06\n",
      "\tBhattacharrya upper bound: (nan, 4.81008361793429)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthewkol186/pton-research/cos597e/cos597efinalproject/ber_metrics.py:123: RuntimeWarning: invalid value encountered in sqrt\n",
      "  lower_bound = 0.5 * (1 - np.sqrt(1 - 4 * p_0 * p_1 * np.exp(-2 * b_dist)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNearest Neighbor upper bound: (0.014386493626438512, 0.02835904485514994)\n",
      "-----Decoupled Sex-------\n",
      "\n",
      "FEMALE\n",
      "\tMahalanobis upper bound: 3.373440743699323e-06\n",
      "\tBhattacharrya upper bound: (9.697311294515343e-05, 0.009847015241205678)\n",
      "\tNearest Neighbor upper bound: (0.018117362749018096, 0.03557824783207715)\n",
      "\n",
      "MALE\n",
      "\tMahalanobis upper bound: 3.081586015114737e-06\n",
      "\tBhattacharrya upper bound: (2.8027514198392112e-08, 0.00016741419718538654)\n",
      "\tNearest Neighbor upper bound: (0.016200466973422645, 0.03187602368653143)\n"
     ]
    }
   ],
   "source": [
    "# for the different groups\n",
    "print(\"----Decoupled Race-----\")\n",
    "X_train, X_test, y_train, y_test = pickle.load(open(path, 'rb'))\n",
    "X_train, y_train = X_train[X_train['IS_RACE_BLACK']==1], y_train[X_train['IS_RACE_BLACK']==1]\n",
    "X_test, y_test = X_test[X_test['IS_RACE_BLACK']==1], y_test[X_test['IS_RACE_BLACK']==1]\n",
    "X_train = X_train.drop(labels=['IS_SEX_M', 'IS_RACE_BLACK', 'IS_RACE_WHITE', 'IS_RACE_HISPANIC', 'IS_RACE_ASIAN', 'IS_SEX_F'], axis=1)\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "mimic_estimator = BEREstimator(X_train, y_train)\n",
    "print()\n",
    "print(\"BLACK\")\n",
    "print(\"\\tMahalanobis upper bound: {}\".format(mimic_estimator.mahalanobis_bound()))\n",
    "print(\"\\tBhattacharrya upper bound: {}\".format(mimic_estimator.bhattacharyya_bound()))\n",
    "print(\"\\tNearest Neighbor upper bound: {}\".format(mimic_estimator.nn_bound()))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = pickle.load(open(path, 'rb'))\n",
    "X_train, y_train = X_train[X_train['IS_RACE_WHITE']==1], y_train[X_train['IS_RACE_WHITE']==1]\n",
    "X_test, y_test = X_test[X_test['IS_RACE_WHITE']==1], y_test[X_test['IS_RACE_WHITE']==1]\n",
    "X_train = X_train.drop(labels=['IS_SEX_M', 'IS_RACE_BLACK', 'IS_RACE_WHITE', 'IS_RACE_HISPANIC', 'IS_RACE_ASIAN', 'IS_SEX_F'], axis=1)\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "mimic_estimator = BEREstimator(X_train, y_train)\n",
    "print()\n",
    "print(\"WHITE\")\n",
    "print(\"\\tMahalanobis upper bound: {}\".format(mimic_estimator.mahalanobis_bound()))\n",
    "print(\"\\tBhattacharrya upper bound: {}\".format(mimic_estimator.bhattacharyya_bound()))\n",
    "print(\"\\tNearest Neighbor upper bound: {}\".format(mimic_estimator.nn_bound()))\n",
    "\n",
    "print(\"-----Decoupled Sex-------\")\n",
    "X_train, X_test, y_train, y_test = pickle.load(open(path, 'rb'))\n",
    "X_train, y_train = X_train[X_train['IS_SEX_F']==1], y_train[X_train['IS_SEX_F']==1]\n",
    "X_test, y_test = X_test[X_test['IS_SEX_F']==1], y_test[X_test['IS_SEX_F']==1]\n",
    "X_train = X_train.drop(labels=['IS_SEX_M', 'IS_RACE_BLACK', 'IS_RACE_WHITE', 'IS_RACE_HISPANIC', 'IS_RACE_ASIAN', 'IS_SEX_F'], axis=1)\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "mimic_estimator = BEREstimator(X_train, y_train)\n",
    "print()\n",
    "print(\"FEMALE\")\n",
    "print(\"\\tMahalanobis upper bound: {}\".format(mimic_estimator.mahalanobis_bound()))\n",
    "print(\"\\tBhattacharrya upper bound: {}\".format(mimic_estimator.bhattacharyya_bound()))\n",
    "print(\"\\tNearest Neighbor upper bound: {}\".format(mimic_estimator.nn_bound()))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = pickle.load(open(path, 'rb'))\n",
    "X_train, y_train = X_train[X_train['IS_SEX_M']==1], y_train[X_train['IS_SEX_M']==1]\n",
    "X_test, y_test = X_test[X_test['IS_SEX_M']==1], y_test[X_test['IS_SEX_M']==1]\n",
    "X_train = X_train.drop(labels=['IS_SEX_M', 'IS_RACE_BLACK', 'IS_RACE_WHITE', 'IS_RACE_HISPANIC', 'IS_RACE_ASIAN', 'IS_SEX_F'], axis=1)\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "mimic_estimator = BEREstimator(X_train, y_train)\n",
    "print()\n",
    "print(\"MALE\")\n",
    "print(\"\\tMahalanobis upper bound: {}\".format(mimic_estimator.mahalanobis_bound()))\n",
    "print(\"\\tBhattacharrya upper bound: {}\".format(mimic_estimator.bhattacharyya_bound()))\n",
    "print(\"\\tNearest Neighbor upper bound: {}\".format(mimic_estimator.nn_bound()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'dict'>,\n",
      "            {'bhatt': {'all_no_demographic': (0.006264390495551109,\n",
      "                                              0.07889960650897043),\n",
      "                       'all_with_demographic': (0.00018925250028173357,\n",
      "                                                0.01375560554002971),\n",
      "                       'black': (0.0, 0.0),\n",
      "                       'female': (0.0, 0.0),\n",
      "                       'male': (0.0, 0.0),\n",
      "                       'white': (0.0, 1.8233875173788025e-11)},\n",
      "             'maha': {'all_no_demographic': 0.23958132853260622,\n",
      "                      'all_with_demographic': 0.2383977285329773,\n",
      "                      'black': 0.14569061587948332,\n",
      "                      'female': 0.12883439717256784,\n",
      "                      'male': 0.28570593841859737,\n",
      "                      'white': 0.24947258980904852},\n",
      "             'nn': {'all_no_demographic': (0.11406516967703556,\n",
      "                                           0.2021086134871693),\n",
      "                    'all_with_demographic': (0.11550679563529465,\n",
      "                                             0.20432995159472184),\n",
      "                    'black': (0.06737175410286744, 0.12566560170394037),\n",
      "                    'female': (0.061022917265815824, 0.11459824166837047),\n",
      "                    'male': (0.1443709356600102, 0.2470559371933268),\n",
      "                    'white': (0.12015098579878503, 0.21142945282073033)}})\n"
     ]
    }
   ],
   "source": [
    "save_estimates('Data/adult_income/processed_data.pkl', 'ber_bounds/adult_bounds.pkl', 'race_Black', 'race_White', 'sex_Female', drop_cols=['race_Other', 'race_Black', 'race_White', 'sex_Male', 'sex_Female'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'dict'>,\n",
      "            {'bhatt': {'all_no_demographic': (0.0, 9.418429699515122e-10),\n",
      "                       'all_with_demographic': (0.00010508635518702292,\n",
      "                                                0.010250624958750676),\n",
      "                       'black': (0.020318962310274413, 0.14108898639124204),\n",
      "                       'female': (nan, nan),\n",
      "                       'male': (nan, nan),\n",
      "                       'white': (0.0, 0.0)},\n",
      "             'maha': {'all_no_demographic': 0.19647007198919228,\n",
      "                      'all_with_demographic': 0.19586095536150863,\n",
      "                      'black': 0.23171405034927542,\n",
      "                      'female': 0.13330424601679006,\n",
      "                      'male': 0.20918503644901543,\n",
      "                      'white': 0.15323894932606172},\n",
      "             'nn': {'all_no_demographic': (0.06533241098704945,\n",
      "                                           0.12212817412333736),\n",
      "                    'all_with_demographic': (0.0823570486352398,\n",
      "                                             0.15114873035066506),\n",
      "                    'black': (0.08154451491172132, 0.14979001399906672),\n",
      "                    'female': (0.06909816364635402, 0.1286472148541114),\n",
      "                    'male': (0.13955973551084727, 0.2401656314699793),\n",
      "                    'white': (0.11003473331478347, 0.1958541815582559)}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthewkol186/pton-research/cos597e/cos597efinalproject/ber_metrics.py:122: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  b_dist = first_term + second_term + third_term\n",
      "/home/matthewkol186/pton-research/cos597e/cos597efinalproject/ber_metrics.py:122: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  b_dist = first_term + second_term + third_term\n"
     ]
    }
   ],
   "source": [
    "save_estimates('Data/compas/processed_violent_nonsingular.pkl', 'ber_bounds/compas_violent_bounds.pkl', 'race_is_african_american', 'race_is_causasian', 'female', drop_cols=['race_is_causasian', 'race_is_african_american', 'race_is_hispanic', 'female'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'dict'>,\n",
      "            {'bhatt': {'all_no_demographic': (nan, nan),\n",
      "                       'all_with_demographic': (0.0, 0.0),\n",
      "                       'black': (0.0018098295397597775, 0.04250357698825829),\n",
      "                       'female': (0.0, 0.0),\n",
      "                       'male': (0.0, 0.0),\n",
      "                       'white': (0.0, 0.0)},\n",
      "             'maha': {'all_no_demographic': 0.42518241798423584,\n",
      "                      'all_with_demographic': 0.4223692451173532,\n",
      "                      'black': 0.4286840162649842,\n",
      "                      'female': 0.3878514393076384,\n",
      "                      'male': 0.42946490529994935,\n",
      "                      'white': 0.4233892364072617},\n",
      "             'nn': {'all_no_demographic': (0.28214522881031767,\n",
      "                                           0.40507859733978235),\n",
      "                    'all_with_demographic': (0.3235442308898998,\n",
      "                                             0.437726723095526),\n",
      "                    'black': (0.4008563430739571, 0.48034107058266223),\n",
      "                    'female': (0.25340151904196406, 0.3783783783783784),\n",
      "                    'male': (0.34468901876110336, 0.4517569982132222),\n",
      "                    'white': (0.2877020430262899, 0.4098591549295775)}})\n"
     ]
    }
   ],
   "source": [
    "save_estimates('Data/compas/processed_arrest_nonsingular.pkl', 'ber_bounds/compas_arrest_bounds.pkl', 'race_is_african_american', 'race_is_causasian', 'female', drop_cols=['race_is_causasian', 'race_is_african_american', 'race_is_hispanic', 'female'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthewkol186/pton-research/cos597e/cos597efinalproject/ber_metrics.py:123: RuntimeWarning: invalid value encountered in sqrt\n",
      "  lower_bound = 0.5 * (1 - np.sqrt(1 - 4 * p_0 * p_1 * np.exp(-2 * b_dist)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'dict'>,\n",
      "            {'bhatt': {'all_no_demographic': (6.879598411496657e-05,\n",
      "                                              0.008294049145473577),\n",
      "                       'all_with_demographic': (5.6900736372267335e-05,\n",
      "                                                0.007543043064869066),\n",
      "                       'black': (3.046635292675015e-05, 0.005519549322914704),\n",
      "                       'female': (9.697311294515343e-05, 0.009847015241205678),\n",
      "                       'male': (2.8027514198392112e-08, 0.00016741419718538654),\n",
      "                       'white': (nan, 4.81008361793429)},\n",
      "             'maha': {'all_no_demographic': 3.2998323778607902e-06,\n",
      "                      'all_with_demographic': 3.2936672086581615e-06,\n",
      "                      'black': 3.15407309387005e-06,\n",
      "                      'female': 3.373440743699323e-06,\n",
      "                      'male': 3.081586015114737e-06,\n",
      "                      'white': 3.440601729633301e-06},\n",
      "             'nn': {'all_no_demographic': (0.014275311838182647,\n",
      "                                           0.02814305462021054),\n",
      "                    'all_with_demographic': (0.02357718593308067,\n",
      "                                             0.04604260447311523),\n",
      "                    'black': (0.03252170221056294, 0.06292808219178082),\n",
      "                    'female': (0.018117362749018096, 0.03557824783207715),\n",
      "                    'male': (0.016200466973422645, 0.03187602368653143),\n",
      "                    'white': (0.014386493626438512, 0.02835904485514994)}})\n"
     ]
    }
   ],
   "source": [
    "save_estimates(\"../mimic_compressed.pkl\", 'ber_bounds/mimic_bounds.pkl', 'IS_RACE_BLACK', 'IS_RACE_WHITE', 'IS_SEX_F', drop_cols=['IS_SEX_M', 'IS_RACE_BLACK', 'IS_RACE_WHITE', 'IS_RACE_HISPANIC', 'IS_RACE_ASIAN', 'IS_SEX_F'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
